{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7d2ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TF/Keras: VGG16 Transfer Learning + Report + 10 Sample Predictions (PRINT ONLY; 2 FIGURES) ===\n",
    "# - Copies dataset once from Drive -> local for faster I/O\n",
    "# - VGG16 (ImageNet) backbone + small custom head\n",
    "# - Prints training/testing time\n",
    "# - Figure 1: Epoch vs Validation Accuracy (baseline run)\n",
    "# - Figure 2: Grid of 10 test images with GT + predicted labels (+ table)\n",
    "# - Amount-of-data vs performance table\n",
    "# - No files are saved\n",
    "\n",
    "import os, time, random, shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "DRIVE_ROOT = \"/content/drive/MyDrive/AI assignment /final\"   # must contain train/val/test\n",
    "LOCAL_ROOT = \"/content/dataset_local/final\"\n",
    "\n",
    "IMG_SIZE  = (224, 224)\n",
    "BATCH     = 32\n",
    "EPOCHS    = 12\n",
    "SEED      = 42\n",
    "AUTOTUNE  = tf.data.AUTOTUNE\n",
    "FRACTIONS = [1.00, 0.50, 0.25]\n",
    "# ---------------------------------------\n",
    "\n",
    "print(\"Physical GPUs:\", tf.config.list_physical_devices('GPU'))\n",
    "try:\n",
    "    tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "except Exception as e:\n",
    "    print(\"Mixed precision not set:\", e)\n",
    "\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# ---------------- Dataset staging ----------------\n",
    "def stage_dataset(drive_root, local_root):\n",
    "    must = [\"train\",\"val\",\"test\"]\n",
    "    for m in must:\n",
    "        if not os.path.exists(os.path.join(drive_root, m)):\n",
    "            raise FileNotFoundError(f\"Missing folder: {m} under {drive_root}\")\n",
    "    if not (os.path.exists(local_root) and all(os.path.exists(os.path.join(local_root,m)) for m in must)):\n",
    "        if os.path.exists(local_root):\n",
    "            shutil.rmtree(local_root)\n",
    "        os.makedirs(os.path.dirname(local_root), exist_ok=True)\n",
    "        shutil.copytree(drive_root, local_root)\n",
    "        print(\"Copied dataset to local:\", local_root)\n",
    "    else:\n",
    "        print(\"Using existing local copy:\", local_root)\n",
    "    return local_root\n",
    "\n",
    "DATA_ROOT = stage_dataset(DRIVE_ROOT, LOCAL_ROOT)\n",
    "\n",
    "# ---------------- Dataset helpers ----------------\n",
    "def list_class_files(dir_path):\n",
    "    classes = sorted([d for d in os.listdir(dir_path) if os.path.isdir(os.path.join(dir_path,d))])\n",
    "    files, labels = [], []\n",
    "    for idx, cname in enumerate(classes):\n",
    "        cdir = os.path.join(dir_path, cname)\n",
    "        for root, _, fnames in os.walk(cdir):\n",
    "            for fn in fnames:\n",
    "                if fn.lower().endswith((\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\",\".tif\",\".tiff\")):\n",
    "                    files.append(os.path.join(root, fn))\n",
    "                    labels.append(idx)\n",
    "    return files, labels, classes\n",
    "\n",
    "def make_ds_from_files(files, labels, batch=BATCH, shuffle=False):\n",
    "    files  = tf.convert_to_tensor(files, dtype=tf.string)\n",
    "    labels = tf.convert_to_tensor(labels, dtype=tf.int32)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((files, labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(files), seed=SEED, reshuffle_each_iteration=True)\n",
    "\n",
    "    def _load(path, y):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "        img = tf.image.resize(img, IMG_SIZE)\n",
    "        img.set_shape(IMG_SIZE + (3,))\n",
    "        img = tf.cast(img, tf.float32)\n",
    "        img = preprocess_input(img)\n",
    "        return img, y\n",
    "\n",
    "    ds = ds.map(_load, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.cache()\n",
    "    ds = ds.batch(batch).prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "def load_full_splits(root):\n",
    "    tr_files, tr_labels, class_names = list_class_files(os.path.join(root, \"train\"))\n",
    "    va_files, va_labels, _ = list_class_files(os.path.join(root, \"val\"))\n",
    "    te_files, te_labels, _ = list_class_files(os.path.join(root, \"test\"))\n",
    "    val_ds  = make_ds_from_files(va_files, va_labels)\n",
    "    test_ds = make_ds_from_files(te_files, te_labels)\n",
    "    meta = {\n",
    "        \"class_names\": class_names,\n",
    "        \"train_files\": tr_files, \"train_labels\": tr_labels,\n",
    "        \"val_files\": va_files,   \"val_labels\": va_labels,\n",
    "        \"test_files\": te_files,  \"test_labels\": te_labels\n",
    "    }\n",
    "    return meta, val_ds, test_ds\n",
    "\n",
    "def make_train_subset(meta, fraction):\n",
    "    tr_files, tr_labels = meta[\"train_files\"], meta[\"train_labels\"]\n",
    "    n_total = len(tr_files)\n",
    "    n_keep = max(1, int(n_total * fraction))\n",
    "    idx = np.random.default_rng(SEED).permutation(n_total)[:n_keep]\n",
    "    files_sub  = [tr_files[i]  for i in idx]\n",
    "    labels_sub = [tr_labels[i] for i in idx]\n",
    "    return make_ds_from_files(files_sub, labels_sub, shuffle=True), n_keep\n",
    "\n",
    "# ---------------- Model ----------------\n",
    "def build_vgg16_transfer(num_classes):\n",
    "    base = VGG16(include_top=False, weights=\"imagenet\", input_shape=IMG_SIZE + (3,))\n",
    "    base.trainable = False\n",
    "\n",
    "    inputs = layers.Input(shape=IMG_SIZE + (3,))\n",
    "    x = base(inputs, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(x)\n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "def compile_model(m):\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=3e-4)\n",
    "    m.compile(optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return m\n",
    "\n",
    "# ---------------- Train once ----------------\n",
    "def train_once(fraction, meta, val_ds, test_ds, show_curve=False, return_model=False):\n",
    "    train_ds, n_train = make_train_subset(meta, fraction)\n",
    "    model = build_vgg16_transfer(len(meta[\"class_names\"]))\n",
    "    compile_model(model)\n",
    "\n",
    "    t0 = time.time()\n",
    "    hist = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, verbose=0)\n",
    "    train_time = time.time() - t0\n",
    "\n",
    "    t1 = time.time()\n",
    "    test_loss, test_acc = model.evaluate(test_ds, verbose=0)\n",
    "    test_time = time.time() - t1\n",
    "\n",
    "    print(f\"\\n[VGG16 Transfer | fraction={fraction:.2f}]  \"\n",
    "          f\"train_samples={n_train}  params={model.count_params():,}  \"\n",
    "          f\"train_time={train_time:.1f}s  test_time={test_time:.1f}s  \"\n",
    "          f\"test_acc={test_acc:.3f}\")\n",
    "\n",
    "    if show_curve:\n",
    "        val_acc = hist.history[\"val_accuracy\"]\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.plot(range(1, EPOCHS+1), val_acc, marker=\"o\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Validation Accuracy\")\n",
    "        plt.title(\"Epoch vs Validation Accuracy\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    summary = {\n",
    "        \"fraction\": fraction,\n",
    "        \"params\": model.count_params(),\n",
    "        \"train_samples\": n_train,\n",
    "        \"train_time_s\": train_time,\n",
    "        \"test_time_s\": test_time,\n",
    "        \"val_acc_last\": hist.history[\"val_accuracy\"][-1],\n",
    "        \"test_acc\": test_acc\n",
    "    }\n",
    "    return (summary, model) if return_model else summary\n",
    "\n",
    "# ---------------- Predictions ----------------\n",
    "def show_predictions(model, meta, k=10):\n",
    "    rng = np.random.default_rng(SEED)\n",
    "    idxs = rng.choice(len(meta[\"test_files\"]), size=k, replace=False)\n",
    "\n",
    "    rows = []\n",
    "    ncols = 5\n",
    "    nrows = int(np.ceil(k / ncols))\n",
    "    plt.figure(figsize=(3*ncols, 2.6*nrows))\n",
    "\n",
    "    for i, idx in enumerate(idxs, 1):\n",
    "        path = meta[\"test_files\"][idx]\n",
    "        y_true = meta[\"test_labels\"][idx]\n",
    "\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "        img = tf.image.resize(img, IMG_SIZE)\n",
    "\n",
    "        img_net = preprocess_input(tf.cast(img, tf.float32))\n",
    "        probs = model(tf.expand_dims(img_net, 0), training=False).numpy()[0]\n",
    "        pred = np.argmax(probs)\n",
    "\n",
    "        gt_name = meta[\"class_names\"][y_true]\n",
    "        pr_name = meta[\"class_names\"][pred]\n",
    "\n",
    "        plt.subplot(nrows, ncols, i)\n",
    "        plt.imshow(tf.cast(img, tf.uint8))\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"gt:{gt_name}\\npred:{pr_name} ({np.max(probs):.2f})\")\n",
    "\n",
    "        rows.append([os.path.basename(path), gt_name, pr_name, np.max(probs)])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\"file\", \"gt\", \"pred\", \"prob\"])\n",
    "    print(df.to_string(index=False))\n",
    "\n",
    "# ================= RUN =================\n",
    "meta, val_ds, test_ds = load_full_splits(DATA_ROOT)\n",
    "print(\"Classes:\", meta[\"class_names\"])\n",
    "print(f\"Samples â†’ train={len(meta['train_files'])}, val={len(meta['val_files'])}, test={len(meta['test_files'])}\")\n",
    "\n",
    "baseline, model = train_once(1.00, meta, val_ds, test_ds, show_curve=True, return_model=True)\n",
    "show_predictions(model, meta, k=10)\n",
    "\n",
    "rows = [train_once(f, meta, val_ds, test_ds) for f in FRACTIONS]\n",
    "print(\"\\n=== Amount of Data vs Performance (VGG16 Transfer) ===\")\n",
    "print(pd.DataFrame(rows)[[\"fraction\",\"train_samples\",\"train_time_s\",\"test_time_s\",\"val_acc_last\",\"test_acc\"]]\n",
    "      .sort_values(\"fraction\"))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
